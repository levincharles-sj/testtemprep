Got it ğŸ‘ â€” thanks for clarifying. Since your QA audience is new to AI in testing, the content should:

* Start with a **clear intro/problem statement**
* Introduce the **tool and vendor**
* Explain **what AI did**
* End with the **measurable results and impact**

Hereâ€™s a concise and structured version:

---

**Case Study: GoCardless â€“ Cutting Test Runtime by 80% with AI**

GoCardless, a global payments provider, was struggling with **long CI test runtimes (up to 300 minutes)**, slowing down developer feedback and releases.

To solve this, they adopted **CloudBees Smart Test**, powered by **Launchableâ€™s AI/ML predictive test selection**. This tool analyzes code changes and past results to **predict which tests are most likely to fail**, so only high-value tests run while low-risk ones are skipped.

The results were dramatic: **test runtime dropped by \~80% (300 mins â†’ 48 mins)**, compute load was cut in half (**8.5K machine hours saved in the first month**), and developers got feedback much faster.

**Outcome:** Faster pipelines, reduced costs, and higher productivity â€“ a clear example of how **AI in QA delivers real-world ROI**.

**Sources:**

* Launchable: [GoCardless Case Study](https://www.launchableinc.com/case-studies/gocardless)
* CloudBees: [GoCardless Accelerates Testing by 80%](https://www.cloudbees.com/customers/gocardless)

---

Would you like me to also add a **1â€“2 line â€œtakeawayâ€** (like a guidance note) at the end, showing QA teams how they could explore similar AI tools in their own projects?
